{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45759196",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from json_repair import repair_json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama.llms import OllamaLLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348c6415",
   "metadata": {},
   "source": [
    "# Variant 1 extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca6872c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"laions_got_talent_enhanced_flash_annotations_and_long_captions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8963c2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "vad_scores_to_emotion = pd.read_csv(\"original_emotion_to_vad_scores.csv\")\n",
    "vad_scores_to_emotion.loc[-1] = [\"Neutral\", \n",
    "0.0, vad_scores_to_emotion[\"pleasure_std\"].quantile(0.5), \n",
    "0.0, vad_scores_to_emotion[\"arousal_std\"].quantile(0.5), \n",
    "0.0, vad_scores_to_emotion[\"dominance_std\"].quantile(0.5)]  # adding a row at the end\n",
    "vad_scores_to_emotion.index = vad_scores_to_emotion.index + 1\n",
    "vad_scores_to_emotion = vad_scores_to_emotion.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf2c5d0",
   "metadata": {},
   "source": [
    "## Extract emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6f5a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "choosen_files = []\n",
    "for file in data_dir.glob(\"*.tar\"):\n",
    "    if \"and\" in file.name:\n",
    "        choosen_files.append(file.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f32bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc = {\"file\": [], \"language\": [], \"emotions\": []}\n",
    "for file in choosen_files:\n",
    "    language = file.split(\"_\")[0]\n",
    "    description = \"_\".join(file.split(\"intense\")[1:])\n",
    "    if \"vocalbursts\" in description:\n",
    "        description = \"\".join(description.split(\"vocalbursts\")[0])\n",
    "    description = description.split(\"and\")\n",
    "    emotions = [emotion.replace(\"_\",\" \").strip() for emotion in description if emotion.strip()]\n",
    "    desc[\"file\"].append(file)\n",
    "    desc[\"language\"].append(language)\n",
    "    desc[\"emotions\"].append(emotions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d065576",
   "metadata": {},
   "outputs": [],
   "source": [
    "choosen_files = [file.replace(\".tar\",\"\") for file in choosen_files if file in answers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57841135",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df = pd.DataFrame(desc)\n",
    "base_df[\"emotions\"] = base_df[\"emotions\"].apply(lambda x: x.strip())\n",
    "base_df[[\"pleasure_mean\", \"pleasure_std\", \"arousal_mean\", \"arousal_std\", \"dominance_mean\", \"dominance_std\"]] = np.nan \n",
    "base_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be9b0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vad_scores_to_emotion = pd.read_csv(\"original_emotion_to_vad_scores.csv\")\n",
    "vad_scores_to_emotion.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e3e230",
   "metadata": {},
   "source": [
    "## Set up the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59068544",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"http://localhost:11434\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d2c60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OllamaLLM(base_url=base_url, model=\"gemma3:27b\", num_ctx=8192*4) # ~18Gb of VRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317eaa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"{system_prompt}\n",
    "    \n",
    "{text}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25b5dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"\"\"You are an assistant that helps summarize emotional labels into a single, most representative term.\n",
    "The user will provide a list of words or phrases, separated by commas. Your task is to carefully analyze the list and respond with one of the allowed labels that best captures the shared meaning or emotional essence of the entire group. Choose the most inclusive and central term.\n",
    "\n",
    "The allowed labels you must use for answer are the following:\n",
    "{'\\n'.join(vad_scores_to_emotion['emotion'].tolist())}\n",
    "Respond with a only a single word â€” no explanations or additional text.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27914df",
   "metadata": {},
   "source": [
    "## Run annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24084fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers_sum = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87464c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, line in enumerate(base_df[\"emotions\"].unique()):\n",
    "    if line in answers_sum:\n",
    "        continue\n",
    "    response  = chain.invoke(\n",
    "        {\n",
    "            \"system_prompt\": system_prompt,\n",
    "            \"text\": line\n",
    "        }\n",
    "    )\n",
    "    answers_sum[line] = response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02e7dec",
   "metadata": {},
   "source": [
    "## Apply answers to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56a51da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add as new column\n",
    "base_df[\"summarized_emotion\"] = base_df[\"emotions\"].map(answers_sum)\n",
    "base_df[\"summarized_emotion\"] = base_df[\"summarized_emotion\"].apply(lambda x: x.strip())\n",
    "base_df[\"summarized_emotion\"] = base_df[\"summarized_emotion\"].apply(lambda x: x.replace(\"*\",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645897e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find summarized_emotion that not in vad_scores_to_emotion.emotion\n",
    "not_in_emotion_to_vad = base_df[~base_df[\"summarized_emotion\"].isin(vad_scores_to_emotion[\"emotion\"])]\n",
    "print(not_in_emotion_to_vad[\"summarized_emotion\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14aec87d",
   "metadata": {},
   "source": [
    "## Retrieve VAD scores for summarized emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd8c85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update pleasure_mean, pleasure_std, arousal_mean, arousal_std, dominance_mean, dominance_std baced on vad_scores_to_emotion\n",
    "def update_vad_scores(row):\n",
    "    emotion = row[\"summarized_emotion\"]\n",
    "    if emotion in vad_scores_to_emotion[\"emotion\"].values:\n",
    "        vad_row = vad_scores_to_emotion[vad_scores_to_emotion[\"emotion\"] == emotion].iloc[0]\n",
    "        row[\"pleasure_mean\"] = vad_row[\"pleasure_mean\"]\n",
    "        row[\"pleasure_std\"] = vad_row[\"pleasure_std\"]\n",
    "        row[\"arousal_mean\"] = vad_row[\"arousal_mean\"]\n",
    "        row[\"arousal_std\"] = vad_row[\"arousal_std\"]\n",
    "        row[\"dominance_mean\"] = vad_row[\"dominance_mean\"]\n",
    "        row[\"dominance_std\"] = vad_row[\"dominance_std\"]\n",
    "    return row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8699377f",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df = base_df.apply(update_vad_scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9c012d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df.to_csv(data_dir / \"final_annotations_with_summarized_emotions.csv\", sep=\";\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3d886d",
   "metadata": {},
   "source": [
    "## Applying scores to audio files in folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5544dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_dir = data_dir / \"extracted_audio\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3abcce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mp3_files.txt is a listing of all mp3 files in all subfolders of audio_dir\n",
    "with open(audio_dir / \"mp3_files.txt\", mode=\"r\") as f:\n",
    "    mp3_files = f.readlines()\n",
    "mp3_files = [file.strip() for file in mp3_files if file.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958746fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_df = pd.DataFrame(mp3_files, columns=[\"file\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6133eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_df[\"parent_dir\"] = audio_df[\"file\"].apply(lambda x: \"/\".join(x.split(\"/\")[:-1])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1727cd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_df = audio_df.merge(base_df, left_on=\"parent_dir\", right_on=\"file\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a3a72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "audio_df = audio_df.drop(columns=[\"file_y\", \"parent_dir\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b9f803",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_df = audio_df.rename(columns={\"file_x\": \"file\"})\n",
    "audio_df = audio_df.rename(columns={\"summarized_emotion\": \"verified_emotion\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4dd80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_df[\"full_path\"] = audio_df[\"file\"].apply(lambda x: str(audio_dir / x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4990dd64",
   "metadata": {},
   "source": [
    "## Save result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fa6d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_df.to_csv(audio_dir / \"final_audio_annotations_with_summarized_emotion.csv\", index=False, sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18621777",
   "metadata": {},
   "source": [
    "# Variant 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f08ebb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eded035a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut substring starting from '#' to '<'\n",
    "def cut_substring(text, start_str, end_str):\n",
    "    start_index = text.find(start_str)\n",
    "    if start_index == -1:\n",
    "        return \"\"  # Return original text if start_str is not found\n",
    "    end_index = text.find(end_str, start_index)\n",
    "    if end_index == -1:\n",
    "        return \"\"  # Return text up to start_str if end_str is not found\n",
    "    return text[start_index+1:end_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8890012",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_markers = [\"</Va\", \"</Ar\", \"</Su\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28066e6",
   "metadata": {},
   "source": [
    "## Run emotion extracion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de3acf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "jsons = {\n",
    "    \"file\": [], #Must be without extension\n",
    "    \"valence\": [],\n",
    "    \"arousal\": [],\n",
    "    \"dominance\": []\n",
    "}\n",
    "for directory in (data_dir / \"extracted_audio\").glob(\"*/\"):\n",
    "    for file in directory.glob(\"*.json\"):\n",
    "        with open(file, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "            lines = []\n",
    "            if \"annotation\" not in data:\n",
    "                continue\n",
    "            for end_marker in end_markers:\n",
    "                for line in data[\"annotation\"].splitlines():\n",
    "                    if end_marker in line:\n",
    "                        line = cut_substring(line, \"#\", end_marker)\n",
    "                        if line == \"\":\n",
    "                            print(f\"Empty line found in file {file.name} for end marker {end_marker}. Skipping.\")\n",
    "                            continue\n",
    "                        lines.append(line.strip())\n",
    "        if len(lines) != 3:\n",
    "            print(f\"Expected 3 lines in {file.name}, got {len(lines)} lines {lines}\")\n",
    "            continue\n",
    "        jsons[\"file\"].append(file.parent / file.stem)  # Store file path without extension\n",
    "        jsons[\"valence\"].append(lines[0])\n",
    "        jsons[\"arousal\"].append(lines[1])\n",
    "        jsons[\"dominance\"].append(lines[2])    \n",
    "df = pd.DataFrame(jsons)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db0b89b",
   "metadata": {},
   "source": [
    "## Save result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291b4ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(data_dir / \"extracted_audio\" /\"vad_descriptions.json\", index=False, sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815f242f",
   "metadata": {},
   "source": [
    "## Set up LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff24c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OllamaLLM(base_url=f\"http://172.22.52.107:11434\", model=\"gemma3:27b\", num_ctx=8192)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cddb53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"{system_prompt}\n",
    "    \n",
    "{text}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec75fe2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b900de63",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"You are helpful AI assistant. You will be provided with short description of the emotion expressed. Your task is to determine the strength and direction of the speaker's emotion.\n",
    "The allowed descriptions and scores are:\n",
    "- Extremely negative: -1\n",
    "- Very negative: -0.75\n",
    "- Weak: -0.5\n",
    "- Slightly negative: -0.25\n",
    "- Neutral: 0\n",
    "- Slightly positive: 0.25\n",
    "- Strong: 0.5\n",
    "- Very positive: 0.75\n",
    "- Extremely positive: 1\n",
    "\n",
    "All generalizations must be made from speaker's perspective, not the subject's.\n",
    "\n",
    "The description will be provided in the following format:\n",
    "Emotion: arousal OR valence OR dominance\n",
    "Description: <description>\n",
    "\n",
    "Please, return only the emotion score without any additional text or explanation.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94607cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"short_description_valence\"] = None\n",
    "df[\"short_description_arousal\"] = None\n",
    "df[\"short_description_dominance\"] = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73237eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "valence_unique = df[\"valence\"].unique()\n",
    "arousal_unique = df[\"arousal\"].unique()\n",
    "dominance_unique = df[\"dominance\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f7a22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "swap_valence = {}\n",
    "swap_arousal = {}\n",
    "swap_dominance = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f399ab6b",
   "metadata": {},
   "source": [
    "## Run annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528fce0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for swap_dict, uniq_vals, dict_emotion in zip([swap_valence, swap_arousal, swap_dominance], [valence_unique, arousal_unique, dominance_unique], [\"valence\", \"arousal\", \"dominance\"]):\n",
    "    for i in range(0, len(uniq_vals), 32):\n",
    "        batch = uniq_vals[i:i+32].tolist()\n",
    "        \n",
    "        text = f\"Emotion: {dict_emotion}\\nDescription: \"\n",
    "        response = chain.batch(\n",
    "            [\n",
    "                {\n",
    "                    \"system_prompt\": system_prompt,\n",
    "                    \"text\": text + desc\n",
    "                } for desc in batch\n",
    "\n",
    "            ])\n",
    "        for j, desc in enumerate(response):\n",
    "            swap_dict[batch[j]] = desc.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7283941",
   "metadata": {},
   "source": [
    "## Apply annotation result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce35a5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for swap_dict, origina_column, new_column in zip([swap_valence, swap_arousal, swap_dominance], [\"valence\",\"arousal\",\"dominance\"] ,[\"short_description_valence\", \"short_description_arousal\", \"short_description_dominance\"]):\n",
    "    df[new_column] = df[origina_column].apply(lambda x: swap_dict[x] if x in swap_dict else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a3fec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.short_description_valence.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1752b79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.short_description_arousal.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b01e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.short_description_dominance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4713d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to float\n",
    "df[\"short_description_arousal\"] = df.short_description_arousal.astype(float)\n",
    "df[\"short_description_valence\"] = df.short_description_valence.astype(float)\n",
    "df[\"short_description_dominance\"] = df.short_description_dominance.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb2d04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "# But only with the necessary columns\n",
    "output_file = data_dir / \"vad_descriptions.csv\"\n",
    "df_to_save = df.drop(columns=[\"valence\", \"arousal\", \"dominance\"])\n",
    "# Rename columns to match the original ones\n",
    "df_to_save = df_to_save.rename(columns={\n",
    "    \"short_description_valence\": \"valence\",\n",
    "    \"short_description_arousal\": \"arousal\",\n",
    "    \"short_description_dominance\": \"dominance\"\n",
    "})\n",
    "df_to_save.to_csv(output_file, index=False, sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e922725",
   "metadata": {},
   "source": [
    "## Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226c5786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the CSV file to ensure it is saved correctly\n",
    "df = pd.read_csv(output_file, sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d78997",
   "metadata": {},
   "source": [
    "### Optional step - resampole to new range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fea208",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_series(series, new_min=-0.7, new_max=0.7):\n",
    "    old_min = series.min()\n",
    "    old_max = series.max()\n",
    "    return ((series - old_min) / (old_max - old_min)) * (new_max - new_min) + new_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d05c3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df[\"valence\"] = resample_series(\n",
    "                df[\"valence\"],\n",
    "                new_min=vad_scores_to_emotion.pleasure_mean.min(),\n",
    "                new_max=vad_scores_to_emotion.pleasure_mean.max())\n",
    "df[\"arousal\"] = resample_series(\n",
    "                df[\"arousal\"], \n",
    "                new_min=vad_scores_to_emotion.arousal_mean.min(), \n",
    "                new_max=vad_scores_to_emotion.arousal_mean.max())\n",
    "df[\"dominance\"] = resample_series(\n",
    "                df[\"dominance\"], \n",
    "                new_min=vad_scores_to_emotion.dominance_mean.min(), \n",
    "                new_max=vad_scores_to_emotion.dominance_mean.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299c4b04",
   "metadata": {},
   "source": [
    "## Apply resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec46b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_resampling(value, stds_mean, stds_std):\n",
    "    if value == -1:\n",
    "        mean = -0.85\n",
    "    elif value == 1:\n",
    "        mean = 0.85\n",
    "    else:\n",
    "        mean = value\n",
    "    std = np.random.normal(stds_mean, stds_std/3)\n",
    "    # Std should not be negative\n",
    "    while std < 0.1 or std > 0.5:\n",
    "        std = np.random.normal(stds_mean, stds_std/3)\n",
    "    mean_gen = np.random.normal(mean, std)\n",
    "    scaling_factor = 1.0\n",
    "    # Mean should be in the range -1 < mean < 1\n",
    "    while mean_gen <= -1 or mean_gen >= 1:\n",
    "        scaling_factor += 0.1\n",
    "        if scaling_factor > 10:\n",
    "            raise ValueError(\"Cannot find suitable mean value in the range -1 < mean < 1, Mean: {}, Std: {}\".format(mean, std))\n",
    "        mean_gen = np.random.normal(mean, std/scaling_factor)\n",
    "    return mean_gen, std\n",
    "\n",
    "def resample_vad_scores(df, emotion_df):\n",
    "    resampled_scores = []\n",
    "    pleasure_mean_std = df[\"valence\"].apply(apply_resampling, args=(emotion_df[\"pleasure_std\"].mean(), emotion_df[\"pleasure_std\"].mean())) # result is tuple!\n",
    "    arousal_mean_std = df[\"arousal\"].apply(apply_resampling, args=(emotion_df[\"arousal_std\"].mean(), emotion_df[\"arousal_std\"].mean()))\n",
    "    dominance_mean_std = df[\"dominance\"].apply(apply_resampling, args=(emotion_df[\"dominance_std\"].mean(), emotion_df[\"dominance_std\"].mean()))\n",
    "    for (pleasure, pleasure_std), (arousal, arousal_std), (dominance, dominance_std) in zip(pleasure_mean_std, arousal_mean_std, dominance_mean_std):\n",
    "        resampled_scores.append({\n",
    "            \"pleasure_mean\": pleasure,\n",
    "            \"pleasure_std\": pleasure_std,\n",
    "            \"arousal_mean\": arousal,\n",
    "            \"arousal_std\": arousal_std,\n",
    "            \"dominance_mean\": dominance,\n",
    "            \"dominance_std\": dominance_std\n",
    "        })\n",
    "    resampled_df = pd.DataFrame(resampled_scores)\n",
    "    return resampled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93ba588",
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_df = resample_vad_scores(df, vad_scores_to_emotion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c437ba1b",
   "metadata": {},
   "source": [
    "## Plot distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31337039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of means and stds\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(resampled_df[\"pleasure_mean\"], kde=True, bins=30)\n",
    "plt.title(\"Distribution of Pleasure Means\")\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(resampled_df[\"pleasure_std\"], kde=True, bins=30)\n",
    "plt.title(\"Distribution of Pleasure Stds\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4fd307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of means and stds\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(resampled_df[\"arousal_mean\"], kde=True, bins=30)\n",
    "plt.title(\"Distribution of Arousal Means\")\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(resampled_df[\"arousal_std\"], kde=True, bins=30)\n",
    "plt.title(\"Distribution of Arousal Stds\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88af45aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of means and stds\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(resampled_df[\"dominance_mean\"], kde=True, bins=30)\n",
    "plt.title(\"Distribution of Dominance Means\")\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(resampled_df[\"Dominance_std\"], kde=True, bins=30)\n",
    "plt.title(\"Distribution of Dominance Stds\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0bfc11",
   "metadata": {},
   "source": [
    "## Merge result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f168ab7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, resampled_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48506f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_emotion(v, a, d, df):\n",
    "    min_distance = float('inf')\n",
    "    closest_emotion = None\n",
    "\n",
    "    distance = np.sqrt((v - df[\"pleasure_mean\"]) ** 2 + (a - df[\"arousal_mean\"]) ** 2 + (d - df[\"dominance_mean\"]) ** 2)\n",
    "    \n",
    "    min_index = distance.idxmin()\n",
    "    closest_emotion = df.iloc[min_index][\"emotion\"]\n",
    "    \n",
    "    return closest_emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6729ba64",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat = []\n",
    "for i in range(vad_scores_to_emotion.shape[0]):\n",
    "    vals = df[[\"pleasure_mean\", \"arousal_mean\", \"dominance_mean\"]].values - vad_scores_to_emotion[[\"pleasure_mean\", \"arousal_mean\", \"dominance_mean\"]].values[i]\n",
    "    vals = np.sqrt(np.sum(vals**2, axis=1))\n",
    "    stat.append(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e18da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat = np.array(stat).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c624ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "verified_emotions = [\n",
    "    vad_scores_to_emotion[\"emotion\"].values[idx] for idx in np.argmin(stat, axis=1)\n",
    "]\n",
    "df[\"verified_emotion\"] = verified_emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de09a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribution of verified emotions \n",
    "plt.figure(figsize=(6, 12))\n",
    "#Use horizontal bar plot\n",
    "sns.countplot(data=df_to_save, y=\"verified_emotion\", order=df[\"verified_emotion\"].value_counts().index)\n",
    "plt.title(\"Distribution of Verified Emotions\")\n",
    "plt.xlabel(\"Count\")\n",
    "plt.ylabel(\"Verified Emotion\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb06e33",
   "metadata": {},
   "source": [
    "## Save result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b858bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save only relevant columns\n",
    "df_to_save = df[[\"file\",\"pleasure_mean\", \"pleasure_std\", \"arousal_mean\", \"arousal_std\", \"dominance_mean\", \"dominance_std\", \"verified_emotion\"]]\n",
    "# Rename file column to full_path\n",
    "df_to_save = df_to_save.rename(columns={\n",
    "    \"file\": \"full_path\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f7968c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = data_dir / \"extracted_audio\" /\"vad_descriptions_resampled.csv\"\n",
    "df_to_save.to_csv(output_file, index=False, sep=\";\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
